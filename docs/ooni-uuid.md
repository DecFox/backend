# On `OOID` OONI measurement UUID

Every measurement already has some set of identifiers described in [OONI Spec](https://github.com/ooni/spec/blob/master/data-formats/df-000-base.md):

- `id` — UUID stamped by client, fallback to `UUID(bytes=(sha1(measurement_blob)[:16]))` at pipeline
- `report_id` — generated by collector on opening `/report` as `{server_now|iso8601}_AS{asn}_{urandom_alnum(50)}`, stamped by client. Old yaml reports have it [generated by pipeline](https://github.com/TheTorProject/ooni-pipeline/blob/4ddc40b6ab5eafc5759eeaf4f23dcf05bdbf6e65/af/shovel/autoclaving.py#L225-L235) as `{start_time}_{hash_cc_asn_test_ver_city_alnum(50)}` that has _at most_ 34 bits entropy for 50-byte string. Some json reports have `null` values, some yaml reports have `urandom_alnum(64)`. Collector and pipeline do not enforce report body and filename to contain same `report_id`!
- `bucket_date` — stamped by pipeline while processing daily bucket
- `${report_filename}` — generated by collector on `/report/{report_id}/close` as `{start_time or test_start_time|iso8601}-{test_name}-{report_id}-AS{asn}-{probe_cc}-….{ext}`. That enforces `report_id` being stored as part of `${report_filename}`. Both `start_time` and `test_start_time` come from client as part of opening `/report`
- `report_filename` — generated by pipeline as `{bucket_date}/${report_filename}` preserving extension of original report file
- `test_start_time` — [pipeline-messed](https://github.com/TheTorProject/ooni-pipeline/blob/4ddc40b6ab5eafc5759eeaf4f23dcf05bdbf6e65/af/shovel/daily_workflow.py#L475-L493) mix of `test_start_time` and `start_time` from raw file
- `measurement_start_time` — pipeline-messed mix of `measurement_start_time`, `test_start_time` and `start_time` from raw file
- `test_started` — float(time_t) present in 19519 measurements as seen by `select count(*) from measurement join residual using (residual_no) where residual->'test_keys' ? 'test_started'`
- `input` — stamped by client, was part of OONI Explorer URL scheme together with `report_id`

All these identifiers are not nice due to following reasons:

- most of them are generated by client, `report_id` may be server-generated, but it's not enforced by there pipeline
- ones having timestamp use client-side timestamp that is not protected from _"time travellers"_
- most of them have low entropy-per-byte ratio
- `test_start_time` and `measurement_start_time` are overriden in pipeline and are different in _canned_ and _autoclaved_ data, `test_started` is not even respected (e.g. it's not promoted to `measurement_start_time` in [this file](https://api.ooni.io/files/download/2012-12-30/20121230T142923Z-RU-AS57668-http_requests-no_report_id-0.1.0-probe.yaml) that has `measurement_start_time` and `test_start_time` equal for all measurements)

It's nice to have int64 identifier having 32 bits allocated for `time_t` as an unique identifier of every measurement collected. It has to respect following constraints and corner-cases:

- max number of measurements per report file is 1000003 (20 bits) for 2014-11-22/20141122T040940Z-US-AS1968-tcp_connect-no_report_id-0.1.0-probe.yaml (top5 is 1000003, 65007, 41889, 40875, 30949)
- max number of measurements per report file in 2018-01-01 … 2018-06-15 time window is ~5000
- client may have wrong wall-clock date, e.g. [2018-06-02 13:05:08](https://api.ooni.io/files/download/2018-06-03/20180802T130309Z-LY-AS37284-ndt-20180602T130508Z_AS37284_Vl7cO6V33OkYBoJgQL403dM2L4arYk7WEAeiPizIW6au6aVfV5-0.2.0-probe.json) reports `test_start_time` fro2018-08-02 13:03:09 from future and [2017-11-13 15:13:05](https://api.ooni.io/files/download/2017-11-14/20031106T094115Z-IQ-AS50710-ndt-20171113T151305Z_AS50710_beuliHbl2zzV3F05or7NIt4ynhZFUCCOjKf1okz1zTov3lvLJU-0.2.0-probe.json) reports from past 2003-11-06 09:41:15.
- client may write wrong timezone in `test_start_time` and `measurement_start_time`, see [2018-06-06 01:56:13](https://api.ooni.io/files/download/2018-06-07/20180606T015613Z-SG-AS7472-http_requests-g14IPb8Zf91k1IUMhj9GfMDoXcOXnjywlCuaxEv0WdHHgRbA6ORUEiezcooJUddc-0.1.0-probe.yaml) having `test_start_time` 2018-06-06 08:56:05 and `measurement_start_time` 2018-06-06 08:56:13 for the first measurement. Correctness of filename-based guess relies on on `Date` HTTP headers in server responses saying 06 Jun 2018 01:56:14 GMT
- report_id may have no timestamp. E.g. [bMr4ueruR8QGX1fjw3dBIOHekiQ2Yxv3prXOO8zw4Qu0NEb0XYU9Em9LyyVaBK3b](https://api.ooni.io/files/download/2018-06-19/20180618T043905Z-RU-AS58191-http_header_field_manipulation-bMr4ueruR8QGX1fjw3dBIOHekiQ2Yxv3prXOO8zw4Qu0NEb0XYU9Em9LyyVaBK3b-0.1.0-probe.yaml) has following _raw_ fields: `start_time`: 1529285941.0 (01:39:01 UTC) , `test_start_time`: 2018-06-18 04:39:05, and `measurement/test_start_time`: 1529285945.0 (01:39:05 UTC). Processed _autoclaved_ file has `test_start_time`: 2018-06-18 01:39:01 and `measurement_start_time`: 2018-06-18 01:39:05. So It suggests that 01:39 is right UTC timestamp. But it's wrong assumption, there is a report coming from _alike_ probe (same version, same AS, close time), [it shows that](https://api.ooni.io/files/download/2018-06-19/20180618T043906Z-RU-AS58191-http_requests-WqMmGyBUMXRxSDGde6Wb8lZMR5vlls0rInMeAo3ro4K6nlSjVwrrBa90fIpNmLzQ-0.1.0-probe.yaml) that also has `test_start_time`: 01:39:01, `measurement_start_time`: 01:46:40, but HTTP `Date` headers explicitly say `Mon, 18 Jun 2018 04:46:35 GMT`. So it means that client-generated-server-serialised timestamp still preserves date and time better than fields within message body. **NB**: UNIX timestamp in raw file is incorrect in this example, it's adjusted for timezone offset!
- generated report_id may still have correct timestamp as well for some yaml files, e.g. [2012-12-30 14:29:23](https://api.ooni.io/files/download/2012-12-30/20121230T142923Z-RU-AS57668-http_requests-no_report_id-0.1.0-probe.yaml)
- report_id may be missing, e.g. [2016-07-31 10:39:22](https://api.ooni.io/files/download/2016-08-01/20160731T103922Z-US-AS14618-dns_injection-no_report_id-0.2.0-probe.json) has generated `report_id` EGTL4PNEIF5K3yNuLA55_gb935U as base64(sha1(raw_file)) in database, but it's not stamped in filename or autoclaved file
- report_id may be duplicate and indicate several retries to submit report, e.g. `2018-05-06/20180505T000008Z-NL-AS9143-web_connectivity-20180505T000008Z_AS9143_YXblHbyqIlBUxqzkwQ344hJM4O19Nx9q2E90RUv4W6yFTi4QyS-0.2.0-probe.json` and `2018-05-10/20180505T000008Z-NL-AS9143-web_connectivity-20180505T000008Z_AS9143_YXblHbyqIlBUxqzkwQ344hJM4O19Nx9q2E90RUv4W6yFTi4QyS-0.2.0-probe.json`
- report_id may be duplicate across _different(!)_ report files, e.g. `2016-02-11/20160210T163242Z-IR-AS201227-http_requests-yZthLDkKNe6IdePf7B1gMgNvRxSMDwNGWD6BB1MWcuY2T3q7oLmDQkjhZARARuic-0.1.0-probe.yaml` and `2016-02-23/20160210T163242Z-IR-AS201227-http_requests-yZthLDkKNe6IdePf7B1gMgNvRxSMDwNGWD6BB1MWcuY2T3q7oLmDQkjhZARARuic-0.1.0-probe.yaml`
- `bucket_date` can be more than a year away from HTTP `Date` timestamps while `report_id` timestamp is reasonable, e.g. [2015-02-01](https://api.ooni.io/files/download/2016-02-27/20150201T095956Z-BE-AS12392-http_requests-no_report_id-0.1.0-probe.yaml), that's likely upload of ancient measurements
- the dataset has 3.6M reports. 80% have unique timestamps, but 753k reports have 316k coincident timestamps, having at most ~20 reports per timestamp
- the dataset has 147M measurements, at least 28 bits are needed to numerate them

Moreover we would like the OONI UUID to have the following properties:

- It's a 64 bit integer (8 bytes) so that it can fits into postgres `bigint` fixed-width native type unlike larger fields
- A sort of "namespace" separation to distinguish pipeline-backfilled OOIDs from collector-stamped OOIDs during rollout of stamping collector
- There is some loose ordering over the ID so that measurements that are close in time have an ID that is of similar cardinality (ex. all measurements from 2018 should have an ID that is `<<` measurements from 2019).

And that's probably incomplete list of corner cases.

## Backfilled OOID

So, given that:

* Timestamps in the measurement body (i.e. `test_start_time`, `measurement_start_time`, etc.) are unreliable
* We have bucket date and filename as a part of "golden" dataset
* We have quite precise timestamp as part of dataset

The proposed schema for _backfilled_ `OOID` (OONI UUID) is the following:

- 32 bits representing time_t stored as `report_id` part of textname, fallback to time_t stored as prefix of the textname basename that usually represents server-side interpretation of client-side `test_start_time` (i.e. we try to get from the data we have available the time that is closest to when the measurement was submitted to the collector, approximating, in the worst case, to the time in which the measurement was added to a bucket). 
- 4 bits set to `1` forming nibble `f` (which is a reserved magic value to indicate the `ooid` was backfilled)
- 28 bits of counter indicating measurement index within report file initialised with 28 least significant bits of `sha1(b'2014-11-18/2014…-probe.yaml')`

Amount of static bits may be reduced to single `1` bit, but 28 bits of entropy are enough to avoid collisions and single `f` nibble looks nice in logs.

### `textname` to `time_t` test vectors

Here is the Python code implementing suggested textname to time_t transformation:

```python
import re, calendar
rex = re.compile(
    r'^(?P<bktyear>20[0-9]{2})-(?P<bktmon>[01][0-9])-(?P<bktday>[0123][0-9])/'
    r'(?P<year>20[0-9]{2})(?P<mon>[01][0-9])(?P<day>[0123][0-9])T(?P<hr>[012][0-9])(?P<min>[0-5][0-9])(?P<sec>[0-5][0-9])Z-'
    r'[A-Z][A-Z]-' # can be replaced with list of ISO country codes
    r'AS(?P<asn>[0-9]{1,10})-' # ASN is 32bit at most
    r'[^-]+-' # test name
    r'(?P<report_id>no_report_id'
        r'|(?P<ridyear>20[0-9]{2})(?P<ridmon>[01][0-9])(?P<ridday>[0123][0-9])T(?P<ridhr>[012][0-9])(?P<ridmin>[0-5][0-9])(?P<ridsec>[0-5][0-9])Z_AS(?P=asn)_[0-9A-Za-z]{50}'
        r'|[A-Za-z0-9]{64}'
    r')-'
    r'0\.[12]\.0-probe\.(?:yaml|json)$') # trailer
def ts(textname):
    m = rex.match(textname)
    if m.group('ridyear') is not None:
        keys = ('ridyear', 'ridmon', 'ridday', 'ridhr', 'ridmin', 'ridsec')
    else:
        keys = ('year', 'mon', 'day', 'hr', 'min', 'sec')
    return calendar.timegm(tuple(int(m.group(_)) for _ in keys))
```

Test vectors:

```
>>> ts('2016-02-11/20160210T163242Z-IR-AS201227-http_requests-yZthLDkKNe6IdePf7B1gMgNvRxSMDwNGWD6BB1MWcuY2T3q7oLmDQkjhZARARuic-0.1.0-probe.yaml')
1455121962 # 2016-02-10 16:32:42 UTC, bucket date is ignored
>>> ts('2017-11-14/20031106T094115Z-IQ-AS50710-ndt-20171113T151305Z_AS50710_beuliHbl2zzV3F05or7NIt4ynhZFUCCOjKf1okz1zTov3lvLJU-0.2.0-probe.json')
1510585985 # 2017-11-13 15:13:05 UTC, time from `report_id` is used
```

### Hash for 32:4:28 scheme

Table describes sha1.hexdigest() offsets producing collision-free OOIDs for all the collected reports up to 2018-06-20 bucket:

counter bits | 7-digit nibble-aligned offset within sha1
-------------|---------------------------------------------
28 | 4 5 6 7 9 11 12 14 16 17 18 19 20 23 26 28 30 31 32 33
27 | 4 5 6   9 11 12 14 16       19 20 23    28 30 31 32 33
26 | 4 5          12 14          19 20 23       30 31 32 33
25 |                             19                      33
24 | not enough entropy within any offset of sha1(textname).hexdigest()

The smallest known timestamp in the current dataset is 0x50bef44d (2012-12-05 07:14:21 UTC), so OOID with first nibble [0-4] may have different binary meaning.
The largest one is 0x5b29a005 (2018-06-20 00:29:57), but that's subject to change :-)

Here is the Python code implementing suggested OOID:

```python
import hashlib
def ooid3(ts, textname, ndx):
    assert textname.startswith(b'20') and textname.endswith((b'.yaml', b'.json')) and ndx >= 0
    ts = ts * 2**32
    colid = 0xf0000000
    cnt = (int(hashlib.sha1(textname).hexdigest()[-7:], 16) + ndx) & 0x0fffffff
    assert (ts & colid) == (ts & cnt) == (colid & cnt) == 0
    return hex(ts | colid | cnt)[2:]
def ooid(textname, ndx):
    return ooid3(ts(textname), textname.encode('ascii'), ndx)
```

Test vectors:

```
>>> ooid('2012-12-05/20121205T071421Z-MM-AS18399-http_invalid_request_line-no_report_id-0.1.0-probe.yaml', 0)
'50bef44df29c69e2'
>>> ooid('2012-12-05/20121205T071421Z-MM-AS18399-http_invalid_request_line-no_report_id-0.1.0-probe.yaml', 1)
'50bef44df29c69e3'
>>> ooid('2018-06-20/20180620T002915Z-DE-AS28753-http_header_field_manipulation-20180620T002917Z_AS28753_ZryhjoYMtU6jEx9TOjDCRuBo5z5te2fLWWj7gkvmkMkbLlnFTi-0.2.0-probe.json', 0)
'5b299fddf5c34544'
```

### Using less bits for counter

If the OOID prefix is the same for all the measurements in the report file, then the minimal possible bit length for the counter is 20 bits. There is a report having 1000003 measurements that needs at least 20 bits.

It's not trivial to have numbering schema that depends only on report file and does not provide collisions across different reports. The outline of collision probability for $time:$static:$counter schema over the whole dataset is estimated below.

It's practical to brute-force a sha1-hmac or siphash key to make counter 24 bit, so it'll be aligned at byte boundary.
The probability of collision of single hash function truncated to 24 bits among those 316k coincident timestamps is ~3e-4, so it's like brute-forcing ~11 bits.

It's not practical to make counter 20 bit with _single_ hash function as it's
equivalent to brute-forcing 186-bit key. But it's practical to have ~128...256
_independent_ keys for hash function to have collision-free 20 bit counter for backfilling.

Estimates of those probabilities are available in [jupyter notebook](./ooid-hash-prob.ipynb).

## Collector-stamped OOID

Collector should use following schema to stamp OOID on every measurement within report file while closing report:

- 32 bits to represent time when the measurement is _received_ according to collector's wall clock
- 8 bits in {0...0xEF} range representing Collector-ID
- 24 bits of counter

int24 counter is enough to stamp 16M measurements per second. Smallest possible
measurement with probe_asn, probe_cc, test_runtime and alike fields is at least
286 bytes.  That makes at least ~38Gbit/s stream.  That's way higher than
throughput of LZ4 decompressor we've seen (11Gbit/s) and/or available wire
speeds (10Gbit/s).

`Collector-ID` is a value stored in configuration file representing unique
collector OS process running somewhere. That limits overall number of
concurrently running collectors with ~240 instances. That's enough for now and
foreseeable future.

Report may be submitted through different collector instances. Collector-ID and
timestamp of the collector receiving the message should be used.

Collector should ensure both during run-time and start-time, that...
- wall clock for specific Collector-ID does not tick backwards
- counter does not overflow within specific second

## OOID representation

Canonical representation of OOID should be hex string.
It's nice to be able to strip first 8 characters and feed them into `date -d
@$(( 0x5b2ce5f4 ))`.
Int64 may be transparently converted to float64 by javascript / some json
libraries leading to annoying errors.
